{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리들 (사용 가능한 라이브러리)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LR\n",
    "# 모델식과 W, b를 직접 정의하고, requires_grad=True로 놓았다.\n",
    "# ** 기본적인 pytorch의 코드 작성 방법\n",
    "# 1. x_train, y_train이 있음\n",
    "# 2. x_train을 선형 조합 OR 기타 등등 식으로 계산하여 prediction을 만드는 식에서,\n",
    "# ~2. 그 식의 파라미터를 설정(LR의 경우, W와 b를 정의하면 됨)\n",
    "# 3. optimizer를 설정\n",
    "# 4. prediction을 이용해 cost function 정의하고,\n",
    "# ~4. step을 밟아가며, optimizer.zero_grad(), cost.backward(), optimizer.step() 을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 준비 : (3, 1). 데이터 하나는 (1,)의 사이즈를 가짐. \n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. W, b 설정\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost 2.6664, W, b 0.02675662934780121, 3.9997951984405518\n",
      "Epoch 200, Cost 0.9156, W, b 0.8913121223449707, 2.520308256149292\n",
      "Epoch 400, Cost 0.3496, W, b 1.3148983716964722, 1.5573971271514893\n",
      "Epoch 600, Cost 0.1335, W, b 1.5766483545303345, 0.9623778462409973\n",
      "Epoch 800, Cost 0.0510, W, b 1.7383946180343628, 0.5946906208992004\n",
      "Epoch 1000, Cost 0.0195, W, b 1.838343620300293, 0.36748287081718445\n",
      "Epoch 1200, Cost 0.0074, W, b 1.9001063108444214, 0.2270819991827011\n",
      "Epoch 1400, Cost 0.0028, W, b 1.9382718801498413, 0.14032267034053802\n",
      "Epoch 1600, Cost 0.0011, W, b 1.9618557691574097, 0.08671092987060547\n",
      "Epoch 1800, Cost 0.0004, W, b 1.9764291048049927, 0.05358210206031799\n",
      "Epoch 2000, Cost 0.0002, W, b 1.9854347705841064, 0.03311028331518173\n"
     ]
    }
   ],
   "source": [
    "# 4. 반복문에서 prediction 및 cost를 계산하고, optimizer를 업데이트\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = x_train * W + b\n",
    "    cost = torch.mean((prediction-y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%200 == 0:\n",
    "        print(f\"Epoch {epoch}, Cost {cost:.4f}, W, b {W.item()}, {b.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9854, 3.9709, 5.9563], grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주의 !!!!!!!!!!!! \n",
    "# x_train.shape : (3, 1)\n",
    "# W.shape : (1,)\n",
    "# x_train.matmul(W) 하면, 왜 (3,) 모양이 되어서 나오는 걸까\n",
    "x_train @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9854],\n",
       "        [3.9709],\n",
       "        [5.9563]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간 과정의 shape를 항상 잘 관찰해야 할 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Cost : 29661.80078125, W : tensor([0.2940, 0.2936, 0.2902]), b : 0.0034\n",
      "Epoch : 20, Cost : 5.957088947296143, W : tensor([0.6807, 0.6785, 0.6677]), b : 0.0079\n",
      "Epoch : 40, Cost : 5.90573787689209, W : tensor([0.6826, 0.6791, 0.6652]), b : 0.0079\n",
      "Epoch : 60, Cost : 5.854844093322754, W : tensor([0.6844, 0.6797, 0.6627]), b : 0.0080\n",
      "Epoch : 80, Cost : 5.804478168487549, W : tensor([0.6863, 0.6803, 0.6602]), b : 0.0080\n",
      "Epoch : 100, Cost : 5.754572868347168, W : tensor([0.6882, 0.6809, 0.6577]), b : 0.0080\n"
     ]
    }
   ],
   "source": [
    "# 2. MLR\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs+1):\n",
    "    prediction = x_train @ W + b\n",
    "    cost = torch.mean((prediction-y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%20==0:\n",
    "        print(f\"Epoch : {epoch}, Cost : {cost}, W : {W.squeeze().detach()}, b : {b.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Cost : 18750.4551\n",
      "Epoch 200 | Cost : 6.1172\n",
      "Epoch 400 | Cost : 5.6906\n",
      "Epoch 600 | Cost : 5.2945\n",
      "Epoch 800 | Cost : 4.9267\n",
      "Epoch 1000 | Cost : 4.5851\n",
      "Epoch 1200 | Cost : 4.2680\n",
      "Epoch 1400 | Cost : 3.9734\n",
      "Epoch 1600 | Cost : 3.6999\n",
      "Epoch 1800 | Cost : 3.4459\n",
      "Epoch 2000 | Cost : 3.2099\n"
     ]
    }
   ],
   "source": [
    "# 3. nn.Module을 활용해서.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터 준비\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "# 모델 작성\n",
    "class MultilinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# 학습\n",
    "model = MultilinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%200==0:\n",
    "        print(f\"Epoch {epoch} | Cost : {cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.7561, 0.8279, 0.4364]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3364], requires_grad=True)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. minibatch & CustomDataset\n",
    "# Dataset과 DataLoader를 사용해서 학습해 보기.\n",
    "# TensorDataset을 이용해서 dataset 인스턴스에 바로 담을 수도 있고, 따로 CustomDataset 클래스를 작성해도 된다.\n",
    "# DataLoader사용법 : Dataset, 그리고 batch size, 그리고 shuffle 인자 (T/F). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Cost:40952.9766\n",
      "Epoch:0, Cost:5362.4189\n",
      "Epoch:0, Cost:4547.7534\n",
      "Epoch:100, Cost:11.3081\n",
      "Epoch:100, Cost:31.5804\n",
      "Epoch:100, Cost:3.9133\n",
      "Epoch:200, Cost:12.0755\n",
      "Epoch:200, Cost:25.8850\n",
      "Epoch:200, Cost:0.4012\n",
      "Epoch:300, Cost:2.5856\n",
      "Epoch:300, Cost:2.5749\n",
      "Epoch:300, Cost:52.3812\n",
      "Epoch:400, Cost:1.0291\n",
      "Epoch:400, Cost:18.2857\n",
      "Epoch:400, Cost:3.9859\n",
      "Epoch:500, Cost:14.4297\n",
      "Epoch:500, Cost:12.2114\n",
      "Epoch:500, Cost:0.0106\n",
      "Epoch:600, Cost:3.0620\n",
      "Epoch:600, Cost:0.8864\n",
      "Epoch:600, Cost:25.5253\n",
      "Epoch:700, Cost:12.7871\n",
      "Epoch:700, Cost:2.5543\n",
      "Epoch:700, Cost:1.4950\n",
      "Epoch:800, Cost:3.3486\n",
      "Epoch:800, Cost:1.4299\n",
      "Epoch:800, Cost:17.1718\n",
      "Epoch:900, Cost:1.4654\n",
      "Epoch:900, Cost:9.4852\n",
      "Epoch:900, Cost:3.8002\n",
      "Epoch:1000, Cost:1.8445\n",
      "Epoch:1000, Cost:1.7906\n",
      "Epoch:1000, Cost:12.3605\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "# 데이터 준비\n",
    "x_train = torch.FloatTensor([[73,  80,  75], \n",
    "                             [93,  88,  93], \n",
    "                             [89,  91,  80], \n",
    "                             [96,  98,  100],   \n",
    "                             [73,  66,  70]])  \n",
    "y_train = torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "# 모델 작성\n",
    "class MultilinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Dataset 작성\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 학습하기\n",
    "model = MultilinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x, y = samples\n",
    "        \n",
    "        prediction = model(x)\n",
    "        cost = F.mse_loss(prediction, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch%100==0:\n",
    "            print(f\"Epoch:{epoch}, Cost:{cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.8215, 0.6957, 0.5244]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3066], requires_grad=True)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Cost : 22618.8730\n",
      "Epoch : 0, Cost : 6950.9160\n",
      "Epoch : 0, Cost : 2654.0042\n",
      "Epoch : 200, Cost : 6.3370\n",
      "Epoch : 200, Cost : 11.5630\n",
      "Epoch : 200, Cost : 3.8626\n",
      "Epoch : 400, Cost : 0.3085\n",
      "Epoch : 400, Cost : 11.0833\n",
      "Epoch : 400, Cost : 6.4813\n",
      "Epoch : 600, Cost : 6.2415\n",
      "Epoch : 600, Cost : 2.8376\n",
      "Epoch : 600, Cost : 2.9009\n",
      "Epoch : 800, Cost : 4.2710\n",
      "Epoch : 800, Cost : 2.0726\n",
      "Epoch : 800, Cost : 6.8733\n",
      "Epoch : 1000, Cost : 3.2646\n",
      "Epoch : 1000, Cost : 1.9684\n",
      "Epoch : 1000, Cost : 3.1057\n",
      "Epoch : 1200, Cost : 2.2911\n",
      "Epoch : 1200, Cost : 3.5613\n",
      "Epoch : 1200, Cost : 2.5720\n",
      "Epoch : 1400, Cost : 1.9408\n",
      "Epoch : 1400, Cost : 1.9342\n",
      "Epoch : 1400, Cost : 1.7581\n",
      "Epoch : 1600, Cost : 0.2715\n",
      "Epoch : 1600, Cost : 1.2632\n",
      "Epoch : 1600, Cost : 3.3385\n",
      "Epoch : 1800, Cost : 0.1990\n",
      "Epoch : 1800, Cost : 0.9911\n",
      "Epoch : 1800, Cost : 2.6824\n",
      "Epoch : 2000, Cost : 0.5320\n",
      "Epoch : 2000, Cost : 1.6380\n",
      "Epoch : 2000, Cost : 0.6093\n"
     ]
    }
   ],
   "source": [
    "# 이번엔 CustomDataset 사용\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 모델 작성\n",
    "class MultilinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultilinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Dataset 작성\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data  =  torch.FloatTensor([[73,  80,  75], \n",
    "                                    [93,  88,  93], \n",
    "                                    [89,  91,  80], \n",
    "                                    [96,  98,  100],   \n",
    "                                    [73,  66,  70]])  \n",
    "        self.y_data  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x, y\n",
    "\n",
    "# 학습하기\n",
    "model = MultilinearRegressionModel()\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x, y = samples\n",
    "        prediction = model(x)\n",
    "        cost = F.mse_loss(prediction, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if epoch%200==0:\n",
    "            print(f\"Epoch : {epoch}, Cost : {cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.0187, 0.7518, 0.2609]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5519], requires_grad=True)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89f8b5fff75b2d8ca621f0b371f1d64751a06b7789195e8887ef7855e4487b82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
